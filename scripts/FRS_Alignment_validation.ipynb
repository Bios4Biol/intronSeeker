{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of FRS pseudo-assembly and library alignement by Hisat2 and STAR aligners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   In order to identify the retained introns in contigs, the strategy to identify candidates is based on split-reads when we re-aligning reads on contigs. Therefore, here, we'll compare two common aligners known to produce these split reads : it's Hisat2 (Kim et al.,2015) and STAR (Doblin et al.,2013). The two aligners will be tested on their ability to retrieve inserted introns in a Full-Random Simulated (FRS) pseudo-assembly (i.e. the length and sequence of the contigs and inserted introns but also the insertion position are totally random simulated) when the contig is only present with intron inthe assembly and when the contig is in two state in the assembly (with and without intron). \n",
    "   \n",
    "### Table of contents\n",
    "\n",
    "* [Description of FRS (Full-Random Simulation) dataset](#desc_frs)\n",
    "    * [Description of the three FRS pseudo-assemblies](#desc_pa)\n",
    "        * [**Table 1** *Comparison  of the three pseudo-assembly with Assemblathon.pl statistics*](#table_1)\n",
    "        * [**Fig 1** *Checking of intron insertion in the pseudo-assemblies*](#fig_1)\n",
    "    * [Description of the FRS reads library](#desc_lib)\n",
    "        * [**Fig 2** *Checking of abundance model of the library*](#fig_2)\n",
    "    * [Description of the four pseudo-assembly/library alignments performed with Hisat2 and STAR](#desc_bam)\n",
    "        * [**Table 2** *Comparison  of the four alignements with samtools flagstats statistics*](#table_2)\n",
    "        * [**Fig 3** *Dotplots of samtools idxstats results (contigs alignement covering) beetween the alignements of Hisat2 and Star for each reference pseudo-assembly.*](#fig_3)\n",
    "* [Analysis of alignments by seaching split reads  and comparing with simulated introns](#ana_frs)\n",
    "    * [Split read signal analysis](#ana_signal)\n",
    "        * [**Fig 4** *Effectives table and barplots of split reads signal detection for STAR and HiSAT2 for the two types of reference.*](#fig_4)\n",
    "        * [**Fig 5** *Counting table and barplots of mapped covering reads' main characteristics.*](#fig_5)\n",
    "        * [**Fig 6** *Counting table and barplots of aligners' duplication capacity of covering reads in mix-states reference.*](#fig_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-031aec8c6be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpysam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#Useful modules :\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import gzip\n",
    "from pprint import pprint\n",
    "from Bio import SeqIO\n",
    "from collections import OrderedDict\n",
    "import plotly as py\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as psp\n",
    "import plotly.io as pio\n",
    "from ipywidgets import widgets\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "if not os.path.exists(\"./.FRS_Alignment_validation_env/\") :\n",
    "    os.mkdir(\"./.FRS_Alignment_validation_env/\")\n",
    "\n",
    "#Useful functions :\n",
    "def parsing_test(items) :\n",
    "    items_of_interest = [\"Number of contigs\",\"Total size of contigs\",\"Longest contig\",\"Shortest contig\",\"Number of contigs > 1K nt\",\"N50 contig length\",\"L50 contig count\"]\n",
    "    if len(items) == 2 and items[0] in items_of_interest :\n",
    "        return True ;\n",
    "    else :\n",
    "        return False ;\n",
    "\n",
    "def parse_assemblathon(filename : str, name : str ) :\n",
    "    with open(filename,\"r\") as f :\n",
    "        assemblathon = { re.split(\"\\s\\s+\",line.strip(),1)[0] : re.split(\"\\s\\s+\",line.strip(),1)[1] for line in f if parsing_test(re.split(\"\\s\\s+\",line.strip(),1))}\n",
    "    return pd.DataFrame(data=assemblathon.values(),index=assemblathon.keys(),columns=[name])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_hisat_all = pd.read_pickle(\"./.FRS_Alignment_validation_env/reads_mapping_Hisat_-_All_with_introns\")\n",
    "mapping_hisat_mixed = pd.read_pickle(\"./.FRS_Alignment_validation_env/reads_mapping_Hisat_-_Mixed-states\")\n",
    "mapping_star_all = pd.read_pickle(\"./.FRS_Alignment_validation_env/reads_mapping_Star_-_All_with_introns\")\n",
    "mapping_star_mixed = pd.read_pickle(\"./.FRS_Alignment_validation_env/reads_mapping_Star_-_Mixed-states\")\n",
    "library = pd.read_pickle(\"./.FRS_Alignment_validation_env/FRS_aln-vld_wo-introns_library_res\")\n",
    "reference_mixed = pd.read_pickle(\"./.FRS_Alignment_validation_env/FRS_align_validation_half-wi-introns.fa.gz\")\n",
    "reference_all = pd.read_pickle(\"./.FRS_Alignment_validation_env/FRS_align_validation_all-wi-introns.fa.gz\")\n",
    "introns = pd.read_pickle(\"./.FRS_Alignment_validation_env/FRS_align_validation_introns.txt.gz\")\n",
    "names = ['All with introns - Hisat2','Mix-states contigs - Hisat2','All with introns - STAR','Mix-states contigs - STAR'] \n",
    "colors = {'All with introns - Hisat2':\"limegreen\",\n",
    "          'Mix-states contigs - Hisat2':\"forestgreen\",\n",
    "          'All with introns - STAR':\"darkorange\",\n",
    "          'Mix-states contigs - STAR':\"chocolate\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_star_all = mapping_star_all.merge(\n",
    "            library,how='outer',\n",
    "            left_on='read',\n",
    "            right_index=True,\n",
    "            suffixes=('','_lib')\n",
    "        ).loc[\n",
    "            :,\n",
    "            [c if c != 'covering' else 'covering_lib' for c in mapping_star_all.columns.to_list()]\n",
    "        ].rename(columns={'covering_lib':'covering'}).reset_index(drop=True)\n",
    "\n",
    "mapping_star_all.loc[lambda df : df.mapped != True,['mapped']] = False\n",
    "mapping_star_all.loc[lambda df : (df.mapped == False)&(df.covering == False),['classe']] = 'TN'\n",
    "mapping_star_all.loc[lambda df : (df.mapped == False)&(df.covering == True),['classe']] = 'FN'\n",
    "\n",
    "mapping_star_mixed = mapping_star_mixed.merge(\n",
    "            library,how='outer',\n",
    "            left_on='read',\n",
    "            right_index=True,\n",
    "            suffixes=('','_lib')\n",
    "        ).loc[\n",
    "            :,\n",
    "            [c if c != 'covering' else 'covering_lib' for c in mapping_star_mixed.columns.to_list()]\n",
    "        ].rename(columns={'covering_lib':'covering'}).reset_index(drop=True)\n",
    "\n",
    "mapping_star_mixed.loc[lambda df : df.mapped != True,['mapped']] = False\n",
    "mapping_star_mixed.loc[lambda df : (df.mapped == False)&(df.covering == False),['classe']] = 'TN'\n",
    "mapping_star_mixed.loc[lambda df : (df.mapped == False)&(df.covering == True),['classe']] = 'FN'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='desc_frs'></a>\n",
    "## Description of FRS (Full-Random Simulation) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='desc_pa'></a>\n",
    "### Description of the three FRS pseudo-assemblies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRS pseudo-assembly without introns: FRS_align-validation_wo-introns.fa\n",
    "\n",
    "   This is the set of full-random simulated contigs without introns. It contains 2000 contigs which have a length beetween 250b to 1500b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_assemblathon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-11539673606b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(\"Assemblathon Analysis of FRS_align-validation_wo-introns.fa :\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0massemblathon_wo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_assemblathon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./FRS_align_validation_wo-introns.assemblathon.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"FRS without introns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_assemblathon' is not defined"
     ]
    }
   ],
   "source": [
    "#print(\"Assemblathon Analysis of FRS_align-validation_wo-introns.fa :\")\n",
    "assemblathon_wo = parse_assemblathon(\"./FRS_align_validation_wo-introns.assemblathon.txt\",\"FRS without introns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRS pseudo-assembly where introns were inserted in each contig : FRS_align-validation_all-wi-introns.fa\n",
    "\n",
    "   This is the same set of simulated contigs of FRS_align-validation_wo-introns.fa but where a full-random simulated intron has been inserted in each intron (i.e. each contig contains one full-random intron). Inserted introns have a length beetween 250b and 750b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Assemblathon Analysis of FRS_align-validation_all-wi-introns.fa :\")\n",
    "assemblathon_all = parse_assemblathon(\"./FRS_align_validation_all-wi-introns.assemblathon.txt\", \"FRS all modified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRS pseudo-assembly where introns were inserted in a random half of the contigs : FRS_align-validation_half-wi-introns.fa\n",
    "\n",
    "   To generate this pseudo-assembly, the two previous pseudo-assembly have been concatenated (i.e. FRS_align-validation_half-wi-introns.fa = FRS_align-validation_wo-introns.fa + FRS_align-validation_all-wi-introns.fa). Therefore, the contigs are, in this dataset, in two states : one version without intron and another version with an introns with a length beetween 250b and 750b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Assemblathon Analysis of FRS_align-validation_half-wi-introns.fa :\")\n",
    "assemblathon_half = parse_assemblathon(\"./FRS_align_validation_half-wi-introns.assemblathon.txt\",\"FRS Mixed states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_1'></a>\n",
    "**Table 1** *Comparison  of the three pseudo-assembly with Assemblathon.pl statistics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fbe33b6fc17a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massemblathon_wo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0massemblathon_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0massemblathon_half\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "display(pd.concat([assemblathon_wo,assemblathon_all,assemblathon_half],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig_1'></a>\n",
    "**Fig 1** *Checking of intron insertion in the pseudo-assemblies*\n",
    "\n",
    "We check that the intron insertion was performed correctly and is random and uniform along the contigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'introns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e1f6a3bc33db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distrib_intron_insertion'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplot_insertion_in_contig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintrons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_on_contig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'introns' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_insertion_in_contig(positions) :\n",
    "    hist = go.Histogram(\n",
    "            x=positions,\n",
    "            xbins=dict(\n",
    "                start=0,\n",
    "                end=100,\n",
    "                size=2),\n",
    "            marker=dict(\n",
    "                color='purple'\n",
    "            )\n",
    "    )\n",
    "    layout = go.Layout(title='Distribution of introns insertion position along the contigs',\n",
    "                       xaxis=dict(\n",
    "                           title=\"% of contig length\"),\n",
    "                       yaxis=dict(\n",
    "                           title=\"Count\"))\n",
    "    fig = go.Figure(data=[hist],layout=layout)\n",
    "    py.offline.iplot(fig, filename='distrib_intron_insertion')\n",
    "    \n",
    "plot_insertion_in_contig(introns['pos_on_contig'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='desc_lib'></a>\n",
    "### Description of the FRS reads library\n",
    "\n",
    "   The reads library has been simulated from the original pseudo-assembly WITHOUT introns with grinder software. It's a paried-end library, with a coverage of 100X. The abundance model follows a uniform law (i.e. all contigs are almost identically covered). The read length folows a normal distribution with N(100;7.5) for parameters. A mutation apparition model is used ; it corresponds to the mutation model of Illumina sequencing : a polynomial (degree 4) law  wich is 3e-3 + 3.3e-8 * i⁴. 80% of these mutations are subsitutions and 20% are indels (Sanger proportions). \n",
    "    Finally, two files were generated : FRS_aln-vld_wo-introns_library_read_1.fastq.gz and FRS_aln-vld_wo-introns_library_read_2.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'library' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6968d13cb932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of the entire library : \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" reads.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'library' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Size of the entire library : \"+str(len(library))+\" reads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig_2'></a>\n",
    "**Fig 2** *Checking of abundance model of the library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rank_file(rank_file) :\n",
    "    with open(rank_file,\"r\") as rf :\n",
    "        ranks = [ligne.lstrip(\"# \").split(\"\\t\") for ligne in rf.read().rstrip().split(\"\\n\")]\n",
    "    return pd.DataFrame(data = ranks[1:], columns=ranks[0] )\n",
    "\n",
    "ranks = parse_rank_file(\"FRS_aln-vld_wo-introns_library-ranks.txt\")\n",
    "real = pd.DataFrame((library.groupby('contig').size()/len(library))*100,columns = ['real_abund_perc']).reset_index()\n",
    "abund = ranks.merge(real,right_on = 'contig',left_on='seq_id',suffixes = ('_grinder','_real'))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = abund['rank'],\n",
    "        y = abund['real_abund_perc'],\n",
    "        mode = 'lines',\n",
    "        name = 'Simulated abundance model'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = abund['rank'],\n",
    "        y = abund['rel_abund_perc'],\n",
    "        mode = 'lines',\n",
    "        name ='Waited abundance model'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Percentage of abundance of each contig in the Full Random generated library',\n",
    "    xaxis=dict(title=\"Contigs\"),\n",
    "    yaxis=dict(title=\"Relative Abundance percentage\",\n",
    "              range=[-0.25,0.5])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='desc_bam'></a>\n",
    "### Description of the four pseudo-assembly/library alignments performed with Hisat2 and STAR\n",
    "\n",
    "   Each pseudo-assembly WITH introns have been aligned with the library with each of the two aligners. Therefore, we have four alignments :\n",
    "    \n",
    "   *  FRS_align-validation_all-wi-introns.fa / FRS-library with Hisat2 : FRS_aln-vld_all-wi-introns_align-hisat.Aligned.sortedByCoord.out.bam\n",
    "   *  FRS_align-validation_half-wi-introns.fa / FRS-library with Hisat2 : FRS_aln-vld_half-wi-introns_align-hisat.Aligned.sortedByCoord.out.bam\n",
    "   *  FRS_align-validation_all-wi-introns.fa / FRS-library with STAR : FRS_aln-vld_all-wi-introns_align-star.Aligned.sortedByCoord.out.bam\n",
    "   *  FRS_align-validation_half-wi-introns.fa / FRS-library with STAR : FRS_aln-vld_half-wi-introns_align-star.Aligned.sortedByCoord.out.bam\n",
    "    \n",
    "   All the alignments have been performed with defaults parameters of corresponding aligner.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_flagstat(filename : str , lib_size : int, name : str) :\n",
    "    flagstat = OrderedDict({})\n",
    "    with open(filename,\"r\") as f :\n",
    "        \n",
    "        first = f.readline().split(\" \",3)\n",
    "        if int(first[2]) == 0 :\n",
    "            qc_failed = False\n",
    "            flagstat[\"Total count\"] = int(first[0])\n",
    "        else :\n",
    "            qc_failed = True\n",
    "            flagstat[\"Total count\"] = [int(first[0]),int(first[2])]\n",
    "            \n",
    "        items_of_interest=[\"secondary\",\n",
    "                           \"supplementary\",\n",
    "                           \"duplicates\",\n",
    "                           \"mapped\",\n",
    "                           \"properly paired\",\n",
    "                           \"singletons\",\n",
    "                           \"with mate mapped to a different chr\"]\n",
    "        \n",
    "        for ligne in f :\n",
    "            values = ligne.rstrip().split(\" \",3)\n",
    "            if not qc_failed and not int(values[0]) == 0 :\n",
    "                item = values[-1].split(\" (\")[0]\n",
    "                if item in items_of_interest :\n",
    "                    if item in [\"mapped\",\"properly paired\",\"singletons\"] :\n",
    "                        flagstat[item] = \"{value} ({percentage}%)\".format(\n",
    "                            value=values[0],\n",
    "                            percentage=round((int(values[0])/(lib_size+flagstat[\"secondary\"]))*100,2))\n",
    "                    else :\n",
    "                        flagstat[item] = int(values[0])\n",
    "                    \n",
    "            elif qc_failed and (not int(values[0]) == 0 or not int(values[2]) == 0) :\n",
    "                item = values[-1].split(\" (\")[0]\n",
    "                if item in items_of_interest :\n",
    "                    if item in [\"mapped\",\"properly paired\",\"singletons\"] :\n",
    "                        flagstat[item] = [\n",
    "                            \"{value} ({percentage}%)\".format(\n",
    "                                value=values[0],\n",
    "                                percentage=round((int(values[0])/(lib_size+flagstat[\"secondary\"]))*100,2)\n",
    "                            ),\n",
    "                            \"{value} ({percentage}%)\".format(\n",
    "                                value=values[2],\n",
    "                                percentage=round((int(values[2])/(lib_size+flagstat[\"secondary\"]))*100,2)\n",
    "                            )]\n",
    "                    else :\n",
    "                        flagstat[item] = [int(values[0]),int(values[2])]\n",
    "            if item == \"with mate mapped to a different chr\" :\n",
    "                break\n",
    "        if not qc_failed :\n",
    "            return pd.DataFrame.from_dict(flagstat,\"index\",columns=[name])\n",
    "        else :\n",
    "            return pd.DataFrame.from_dict(flagstat,\"index\",columns=pd.MultiIndex.from_tuples([(name,\"QC-passed\"),(name,\"QC-failed\")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flag_all_hisat = parse_flagstat(\"./FRS_aln-vld_all-wi-introns_align-hisat.Aligned.sortedByCoord.out.flagstat.txt\", len(library),\"All with introns - Hisat2\")\n",
    "flag_half_hisat = parse_flagstat(\"./FRS_aln-vld_half-wi-introns_align-hisat.Aligned.sortedByCoord.out.flagstat.txt\", len(library),\"Mix-states contigs - Hisat2\")\n",
    "flag_all_star = parse_flagstat(\"./FRS_aln-vld_all-wi-introns_align-star.Aligned.sortedByCoord.out.flagstat.txt\", len(library),\"All with introns - STAR\")\n",
    "flag_half_star = parse_flagstat(\"./FRS_aln-vld_half-wi-introns_align-star.Aligned.sortedByCoord.out.flagstat.txt\", len(library),\"Mix-states contigs - STAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_2'></a>\n",
    "**Table 2** *Comparison  of the four alignements with samtools flagstats statistics*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total counts of reads to map (library size) : \"+str(len(library))+\" reads\\n\")\n",
    "display(pd.concat([flag_all_hisat,flag_half_hisat,flag_all_star,flag_half_star],axis=1,sort=False).fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig_3'></a>\n",
    "**Fig 3** *Dotplots of samtools idxstats results (contigs alignement covering) beetween the alignements of Hisat2 and Star for each reference pseudo-assembly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_idxstats(idx) :\n",
    "    return pd.read_csv(\n",
    "        idx,\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        names = ['contig','length','mapped_reads','unmapped_reads'],\n",
    "        index_col = 'contig'\n",
    "    )\n",
    "\n",
    "hisat_all_idxstats = parse_idxstats('FRS_aln-vld_all-wi-introns_align-hisat.Aligned.sortedByCoord.out.idxstats.txt')\n",
    "star_all_idxstats = parse_idxstats('FRS_aln-vld_all-wi-introns_align-star.Aligned.sortedByCoord.out.idxstats.txt')\n",
    "\n",
    "all_idxstats = hisat_all_idxstats.join(star_all_idxstats,lsuffix='_Hisat',rsuffix='_Star').sort_values(by='mapped_reads_Hisat')\n",
    "\n",
    "fig  = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = all_idxstats['mapped_reads_Hisat'],\n",
    "        y = all_idxstats['mapped_reads_Star'],\n",
    "        mode='markers',\n",
    "        name='Contigs',\n",
    "        text=all_idxstats.index\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(0,2000)),\n",
    "        y=list(range(0,2000)),\n",
    "        mode='lines',\n",
    "        name='Diagonal'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'Dotplot of read quantification by contig according to aligners (All with introns)',\n",
    "    width=700,\n",
    "    height=700,\n",
    "    xaxis=dict(title='Hisat idxstats',range=[0,2000]),\n",
    "    yaxis=dict(title='Star idxstats',range=[0,2000])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisat_mix_idxstats = parse_idxstats('FRS_aln-vld_half-wi-introns_align-hisat.Aligned.sortedByCoord.out.idxstats.txt')\n",
    "star_mix_idxstats = parse_idxstats('FRS_aln-vld_half-wi-introns_align-star.Aligned.sortedByCoord.out.idxstats.txt')\n",
    "\n",
    "half_idxstats = hisat_mix_idxstats.join(star_mix_idxstats,lsuffix='_Hisat',rsuffix='_Star').sort_values(by='mapped_reads_Hisat')\n",
    "\n",
    "\n",
    "fig  = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = half_idxstats.loc[lambda df : df.index.str.endswith('.ori')==True,'mapped_reads_Hisat'],\n",
    "        y = half_idxstats.loc[lambda df : df.index.str.endswith('.ori')==True,'mapped_reads_Star'],\n",
    "        mode='markers',\n",
    "        name='Contigs without intron',\n",
    "        marker_color='orchid',\n",
    "        text=half_idxstats.loc[lambda df : df.index.str.endswith('.ori')==True].index\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x = half_idxstats.loc[lambda df : df.index.str.endswith('.ori')==False,'mapped_reads_Hisat'],\n",
    "        y = half_idxstats.loc[lambda df : df.index.str.endswith('.ori')==False,'mapped_reads_Star'],\n",
    "        mode='markers',\n",
    "        name='Contigs with intron(s)',\n",
    "        marker_color='teal',\n",
    "        text=half_idxstats.loc[lambda df : df.index.str.endswith('.ori')==False].index\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(range(0,2000)),\n",
    "        y=list(range(0,2000)),\n",
    "        mode='lines',\n",
    "        name='Diagonal',\n",
    "        marker_color = 'red'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'Dotplot of read quantification by contig according to aligners (Mixed-states)',\n",
    "    width=700,\n",
    "    height=700,\n",
    "    xaxis=dict(title='Hisat idxstats',range=[0,2000]),\n",
    "    yaxis=dict(title='Star idxstats',range=[0,2000])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ana_frs'></a>\n",
    "## Analysis of alignments by seaching split reads  and comparing with simulated introns\n",
    "\n",
    "<a id='ana_signal'></a>\n",
    "### Split read signal analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig_4'></a>\n",
    "**Fig 4** *Effectives table and barplots of split reads signal detection for STAR and HiSAT2 for the two types of reference.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_reads(*args,**kwargs) :\n",
    "    series = [[],[]]\n",
    "    colors = kwargs['colors']\n",
    "    \n",
    "    fig = psp.make_subplots(\n",
    "        rows = 2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.03,\n",
    "        specs=[[{\"type\":\"table\"}],\n",
    "               [{\"type\":\"bar\"}]])\n",
    "\n",
    "    for name,val in args :\n",
    "        for idx,val in enumerate([val,val.loc[lambda df : df.contig == df.contig.str.rstrip(\".ori\"),:]]) :\n",
    "            s = val.loc[:,'classe'].value_counts()\n",
    "            s.name=name\n",
    "            \n",
    "        \n",
    "            if idx == 0 :\n",
    "                visibility = True\n",
    "            else :\n",
    "                visibility = False\n",
    "        \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    visible=visibility,\n",
    "                    x=s.index[1:],\n",
    "                    y=s.values[1:]/s.sum()*100,\n",
    "                    name = s.name,\n",
    "                    marker_color=colors[s.name]\n",
    "                ),row=2,col=1)\n",
    "            \n",
    "            s['Total'] = s.sum()\n",
    "            series[idx].append(s)\n",
    "\n",
    "    for idx,serie in enumerate(series) :\n",
    "        table = pd.concat(serie,axis=1,sort=False).fillna(0)\n",
    "        \n",
    "        \n",
    "        if idx == 0 :\n",
    "            visibility = True\n",
    "        else :\n",
    "            visibility = False\n",
    "            \n",
    "        fig.add_trace(\n",
    "            go.Table(\n",
    "                visible=visibility,\n",
    "                columnwidth=[40,80],\n",
    "                header = dict(\n",
    "                    values=[\"\",*[c.join([\"<b>\",\"</b>\"]) for c in table.columns.to_list()]],\n",
    "                    fill_color='lightgrey'\n",
    "                    ),\n",
    "                cells = dict(\n",
    "                    values=[[v.join([\"<b>\",\"</b>\"]) for v in list(table.reset_index().T.values)[0]],\n",
    "                           *list(table.reset_index().T.values)[1:]],\n",
    "                    fill=dict(color=['lightgrey','lavender'])\n",
    "                    )\n",
    "                ),\n",
    "            row=1,col=1)\n",
    "    \n",
    "#     print(vars(fig.layout))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        height=700,\n",
    "        legend=dict(\n",
    "            x=-0.4,y=0.40\n",
    "            ),\n",
    "        updatemenus=[\n",
    "            go.layout.Updatemenu(\n",
    "                buttons=[\n",
    "                    dict(\n",
    "                        args=[{\"visible\":[True,False]}],\n",
    "                        label='All alignements',\n",
    "                        method='restyle'\n",
    "                        ),\n",
    "                    dict(\n",
    "                        args=[{\"visible\":[False,True]}],\n",
    "                        label='Alignements on contigs with introns',\n",
    "                        method='restyle'\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    fig.show()\n",
    "    \n",
    "plot_class_reads(*zip(names,[\n",
    "                    mapping_hisat_all,\n",
    "                    mapping_hisat_mixed,\n",
    "                    mapping_star_all,\n",
    "                    mapping_star_mixed\n",
    "                    ]),\n",
    "                colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig_5'></a>\n",
    "**Fig 5** *Counting table and barplots of mapped covering reads' main characteristics.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covering_reads(*args,**kwargs) :\n",
    "    series=[]\n",
    "    fig = go.Figure()\n",
    "    for name, val in args :\n",
    "        s = pd.Series(name=name)\n",
    "        s['Covering']=len(val)\n",
    "        s['Unmapped']=len(val.loc[lambda df : df.mapped == False])\n",
    "        tmp = val.merge(library,left_on='read',right_index=True,suffixes=(\"\",\"_lib\"))\n",
    "        s['Mismapped'] = len(tmp.loc[lambda df : (df.contig.str.rstrip('.ori') != df.contig_lib.str.rstrip('.ori'))& (df.mapped == True)])\n",
    "        s['Unsplit'] = len(val.loc[lambda df : (df.mapped==True)&(df.split==False)])\n",
    "        s['Missplit'] = len(val.loc[lambda df : (df.split==True)&(df.missplit==True)])\n",
    "        s['Correct splitting'] = len(val.loc[lambda df : df.classe == 'TP'])\n",
    "        series.append(s)\n",
    "        \n",
    "        to_plot = s[['Unmapped','Unsplit','Correct splitting']]/s['Covering']*100\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                    x=to_plot.index,\n",
    "                    y=to_plot.values,\n",
    "                    name = s.name,\n",
    "                    marker_color=colors[s.name]\n",
    "            ))\n",
    "    table = pd.concat(series,axis=1,sort=False)\n",
    "    display(table)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Global mapping results on introns-covering reads',\n",
    "        xaxis=dict(title='Lectures charecteristics'),\n",
    "        yaxis=dict(title='Percentage of total covering reads alignements')\n",
    "        )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "plot_covering_reads(*zip(names,[\n",
    "                    mapping_hisat_all.loc[lambda df : df.covering == True,:],\n",
    "                    mapping_hisat_mixed.loc[lambda df : df.covering == True,:],\n",
    "                    mapping_star_all.loc[lambda df : df.covering == True,:],\n",
    "                    mapping_star_mixed.loc[lambda df : df.covering == True,:]\n",
    "                    ]),\n",
    "                colors=colors,\n",
    "                library=library)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig_6'></a>\n",
    "**Fig 6** *Counting table and barplots of aligners' duplication capacity of covering reads in mix-states reference.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reads_duplication(*args,**kwargs) :\n",
    "    series=[]\n",
    "    fig = go.Figure()\n",
    "    for name,val in args :\n",
    "        s = pd.Series(name=name)\n",
    "        mer_val = val.merge(library,left_on='read',right_index=True,suffixes=(\"\",\"_lib\")).loc[lambda df : (df.contig.str.rstrip('.ori') == df.contig_lib.str.rstrip('.ori'))]\n",
    "        s['Correctly mapped covering reads'] = len(mer_val)\n",
    "        no_dupl= mer_val.loc[mer_val['read'].duplicated(keep=False)==False,:]\n",
    "        s['Mapped only on full contig'] =len(no_dupl.loc[lambda df : df.contig.str.endswith('.ori') == True])\n",
    "        s['Mapped only on split contig'] =len(no_dupl.loc[lambda df : df.contig.str.endswith('.ori') == False])\n",
    "        s['Unsplit/Missplit on split contig']=len(no_dupl.loc[lambda df : (df.contig.str.endswith('.ori') == False)&((df.split==False)|(df.missplit==True))])\n",
    "        s['Correct only on split contig']=len(no_dupl.loc[lambda df : (df.contig.str.endswith('.ori') == False)&(df.split==True)&(df.missplit==False)])\n",
    "        dupl = mer_val.loc[mer_val['read'].duplicated(keep=False)==True,:]\n",
    "        s['Duplicated on both contigs']= len(dupl)\n",
    "        s['Duplicated and missplit/unsplit on split contig']=len(dupl.loc[lambda df : (df.contig.str.endswith('.ori') == False)&((df.split==False)|(df.missplit==True))])\n",
    "        s['Duplicated and correct split']=len(dupl.loc[lambda df : (df.contig.str.endswith('.ori') == False)&(df.split==True)&(df.missplit==False)])\n",
    "        series.append(s)\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=s.index,\n",
    "                y=s.values,\n",
    "                name = s.name,\n",
    "                marker_color=colors[s.name],\n",
    "                text=s.values,\n",
    "                textposition='auto'    \n",
    "            ))\n",
    "    table = pd.concat(series,axis=1,sort=False)\n",
    "    display(table)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Analysis of duplicated alignements on the two-satest contigs (all introns-covering reads)',\n",
    "        xaxis=dict(title='Groups'),\n",
    "        yaxis=dict(title='Count')\n",
    "        )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "plot_reads_duplication(*zip([names[1],names[3]],[\n",
    "                    mapping_hisat_mixed.loc[lambda df : df.covering == True,:],\n",
    "                    mapping_star_mixed.loc[lambda df : df.covering == True,:]\n",
    "                    ]),\n",
    "                colors=colors,\n",
    "                library=library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_global_results(global_dfs : list,complement=\"\") :\n",
    "#     print(\"Table of global intron detection results \"+complement)\n",
    "#     display(pd.concat(global_dfs,axis = 1))\n",
    "\n",
    "\n",
    "\n",
    "# def plot_percent_correct(series : list,complement=\"\") :\n",
    "#     boxplots=[]\n",
    "#     for s in series :\n",
    "#         box = go.Box(\n",
    "#             x=s.values,\n",
    "#             name=s.name)\n",
    "#         boxplots.append(box)\n",
    "    \n",
    "#     layout = go.Layout(title= \"Boxplot of correct lectures percentage for VP class introns \"+complement,\n",
    "#             xaxis = dict(title=\"%_correct\")) \n",
    "#     fig = go.Figure(data=boxplots,layout=layout)\n",
    "#     py.offline.iplot(fig,filename=\"box_%_correct\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# def plot_introns_detection(series : list,complement=\"\") :\n",
    "#     barplots=[]\n",
    "#     print(\"Table of intron detection\")\n",
    "#     display(pd.concat(series,axis=1))\n",
    "#     for s in series :\n",
    "#         bar = go.Bar(\n",
    "#             x=s.index,\n",
    "#             y=s.values,\n",
    "#             name = s.name,\n",
    "#             text=s.values,\n",
    "#             textposition=\"auto\"\n",
    "#             )\n",
    "#         barplots.append(bar)\n",
    "    \n",
    "#     layout = go.Layout(title='Global results on introns detection '+complement,\n",
    "#                        xaxis=dict(\n",
    "#                            title=\"Groups\"),\n",
    "#                        yaxis=dict(\n",
    "#                            title=\"Count\"))\n",
    "#     fig = go.Figure(data=barplots,layout=layout)\n",
    "#     py.offline.iplot(fig, filename='introns_detection_bar')\n",
    "\n",
    "\n",
    "\n",
    "# def norm_each_bin(bining) :\n",
    "    \n",
    "#     if bining[\"correct\"].all() and not bining.empty  :\n",
    "#         return float(100)\n",
    "#     elif bining[\"correct\"].any() and not bining.empty :\n",
    "#         return (bining.groupby(\"correct\").size()[True]/len(bining))*100\n",
    "#     else :\n",
    "#         return float(0)\n",
    "    \n",
    "# def histplot_pos_on_reads(data : list) :\n",
    "#     hists=[]\n",
    "#     for d in data :\n",
    "#         df = list(d.values()).pop()\n",
    "#         name = list(d.keys()).pop()\n",
    "#         factor = pd.cut(list(df[\"position\"]), range(0,101,2),right=False)\n",
    "#         positions_norm = df.groupby(factor).apply(norm_each_bin)\n",
    "#         hist = go.Bar(\n",
    "#             x=[n+1 for n in range(0,100,2)],\n",
    "#             y=positions_norm.values,\n",
    "#             width=[2]*50,\n",
    "#             name = name,\n",
    "#             hovertemplate=\"<b>Value : %{y:.2f}</b><br>\"\n",
    "#                           \"<i>Interval : %{text}</i>\",\n",
    "#             text = [\"{m}-{n}\".format(m=k,n=k+2) for k in range(0,100,2)]\n",
    "#             )\n",
    "#         hists.append(hist)\n",
    "#     layout = go.Layout(\n",
    "#         title='Correct spliting counting depending on intron insertion position on read (in % of read length)',\n",
    "#         xaxis1=dict(\n",
    "#             title='% of read length'\n",
    "#         ),\n",
    "#         xaxis2=dict(\n",
    "#             title='% of read length'\n",
    "#         ),\n",
    "#         xaxis3=dict(\n",
    "#             title='% of read length'\n",
    "#         ),\n",
    "#         xaxis4=dict(\n",
    "#             title='% of read length'\n",
    "#         ),\n",
    "#         yaxis1=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         ),\n",
    "#         yaxis2=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         ),\n",
    "#         yaxis3=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         ),\n",
    "#         yaxis4=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         )\n",
    "#     )\n",
    "#     fig = tools.make_subplots(rows=2, cols=2,shared_yaxes=True)\n",
    "#     fig.append_trace(hists[0], 1, 1)\n",
    "#     fig.append_trace(hists[1], 1, 2)\n",
    "#     fig.append_trace(hists[2], 2, 1)\n",
    "#     fig.append_trace(hists[3], 2, 2)\n",
    "#     fig['layout'].update(layout)\n",
    "#     py.offline.iplot(fig, filename='styled histogram')\n",
    "\n",
    "# def histplot_pos_on_contig(data : list) :\n",
    "#     hists=[]\n",
    "#     for d in data :\n",
    "#         df = list(d.values()).pop()\n",
    "#         name = list(d.keys()).pop()\n",
    "#         factor = pd.cut(list(df[\"position\"]), range(0,101,2),right=False)\n",
    "#         positions_norm = df.groupby(factor).apply(norm_each_bin)\n",
    "#         hist = go.Bar(\n",
    "#             x=[n+1 for n in range(0,100,2)],\n",
    "#             y=positions_norm.values,\n",
    "#             width=[2]*50,\n",
    "#             name = name,\n",
    "#             hovertemplate=\"<b>Value : %{y:.2f}</b><br>\"\n",
    "#                           \"<i>Interval : %{text}</i>\",\n",
    "#             text = [\"{m}-{n}\".format(m=k,n=k+2) for k in range(0,100,2)]\n",
    "#             )\n",
    "#         hists.append(hist)\n",
    "#         layout = go.Layout(\n",
    "#     title='Correct spliting counting depending on intron insertion position on contig (in % of contig length)',\n",
    "#         xaxis1=dict(\n",
    "#             title='% of contig length'\n",
    "#         ),\n",
    "#         xaxis2=dict(\n",
    "#             title='% of contig length'\n",
    "#         ),\n",
    "#         xaxis3=dict(\n",
    "#             title='% of contig length'\n",
    "#         ),\n",
    "#         xaxis4=dict(\n",
    "#             title='% of contig length'\n",
    "#         ),\n",
    "#         yaxis1=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         ),\n",
    "#         yaxis2=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         ),\n",
    "#         yaxis3=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         ),\n",
    "#         yaxis4=dict(\n",
    "#             title='% of correct split reads'\n",
    "#         )\n",
    "#     )\n",
    "#     fig = tools.make_subplots(rows=2, cols=2,shared_yaxes=True)\n",
    "#     fig.append_trace(hists[0], 1, 1)\n",
    "#     fig.append_trace(hists[1], 1, 2)\n",
    "#     fig.append_trace(hists[2], 2, 1)\n",
    "#     fig.append_trace(hists[3], 2, 2)\n",
    "#     fig['layout'].update(layout)\n",
    "#     py.offline.iplot(fig, filename='styled histogram')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the four alignements considering all introns-covering reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_reads_duplication([res[4] for res in analysis_res if res[4] is not None],\"(all introns-covering reads)\")\n",
    "# print_global_results([res[0] for res in analysis_res],\"(all introns-covering reads)\")\n",
    "# plot_percent_correct([res[2] for res in analysis_res],\"(all introns-covering reads)\")\n",
    "# plot_introns_detection([res[3] for res in analysis_res],\"(all introns-covering reads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Correct splitting depends on intron insertion in READS\")\n",
    "# histplot_pos_on_reads([res[5] for res in analysis_res])\n",
    "# print(\"Correct splitting depends on intron insertion in CONTIGS\")\n",
    "# histplot_pos_on_contig([res[6] for res in analysis_res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the four alignements considering only the reads where introns are inserted at 10 bases in minimum from borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_res_10 = []\n",
    "# analysis_res_10.append(alignement_analysis(\"./FRS_aln-vld_all-wi-introns_align-hisat.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_all-wi-introns.fa\",\"./FRS_align-validation_all-introns-coord.txt\",library,\"All with introns - Hisat2 - margin 10\",10))\n",
    "# analysis_res_10.append(alignement_analysis(\"./FRS_aln-vld_half-wi-introns_align-hisat.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_half-wi-introns.fa\",\"./FRS_align-validation_half-introns-coord.txt\",library,\"Mix-states contigs - Hisat2 - margin 10\",10,mix=True))\n",
    "# analysis_res_10.append(alignement_analysis(\"./FRS_aln-vld_all-wi-introns_align-star.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_all-wi-introns.fa\",\"./FRS_align-validation_all-introns-coord.txt\",library,\"All with introns - STAR - margin 10\",10))\n",
    "# analysis_res_10.append(alignement_analysis(\"./FRS_aln-vld_half-wi-introns_align-star.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_half-wi-introns.fa\",\"./FRS_align-validation_half-introns-coord.txt\",library,\"Mix-states contigs - STAR - margin 10\",10,mix=True))\n",
    "\n",
    "# plot_covering_reads([res[1] for res in analysis_res_10],\"(only reads with 10 bases margin)\")\n",
    "# plot_reads_duplication([res[4] for res in analysis_res_10 if res[4] is not None],\"(only reads with 10 bases margin)\")\n",
    "# print_global_results([res[0] for res in analysis_res_10],\"(only reads with 10 bases margin)\")\n",
    "# plot_percent_correct([res[2] for res in analysis_res_10],\"(only reads with 10 bases margin)\")\n",
    "# plot_introns_detection([res[3] for res in analysis_res_10],\"(only reads with 10 bases margin)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the four alignements considering only the reads where introns are inserted at 20 bases in minimum from borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_res_20 = []\n",
    "# analysis_res_20.append(alignement_analysis(\"./FRS_aln-vld_all-wi-introns_align-hisat.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_all-wi-introns.fa\",\"./FRS_align-validation_all-introns-coord.txt\",library,\"All with introns - Hisat2 - margin 20\",20))\n",
    "# analysis_res_20.append(alignement_analysis(\"./FRS_aln-vld_half-wi-introns_align-hisat.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_half-wi-introns.fa\",\"./FRS_align-validation_half-introns-coord.txt\",library,\"Mix-states contigs - Hisat2 - margin 20\",20,mix=True))\n",
    "# analysis_res_20.append(alignement_analysis(\"./FRS_aln-vld_all-wi-introns_align-star.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_all-wi-introns.fa\",\"./FRS_align-validation_all-introns-coord.txt\",library,\"All with introns - STAR - margin 20\",20))\n",
    "# analysis_res_20.append(alignement_analysis(\"./FRS_aln-vld_half-wi-introns_align-star.Aligned.sortedByCoord.out.bam\",\"./FRS_align-validation_half-wi-introns.fa\",\"./FRS_align-validation_half-introns-coord.txt\",library,\"Mix-states contigs - STAR - margin 20\",20,mix=True))\n",
    "\n",
    "# plot_covering_reads([res[1] for res in analysis_res_20],\"(only reads with 20 bases margin)\")  \n",
    "# plot_reads_duplication([res[4] for res in analysis_res_20 if res[4] is not None],\"(only reads with 20 bases margin)\")\n",
    "# print_global_results([res[0] for res in analysis_res_20],\"(only reads with 20 bases margin)\")\n",
    "# plot_percent_correct([res[2] for res in analysis_res_20],\"(only reads with 20 bases margin)\")\n",
    "# plot_introns_detection([res[3] for res in analysis_res_20],\"(only reads with 20 bases margin)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}